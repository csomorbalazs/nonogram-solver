{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn-solver.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3w9ahelrKOq"
      },
      "source": [
        "### Nonogram class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LfgRhHKrAyj"
      },
      "source": [
        "from typing import List, Tuple\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import itertools\r\n",
        "import math\r\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqLx4xsUrD0e"
      },
      "source": [
        "def pad(list, target_len):\r\n",
        "    return [0]*(target_len - len(list)) + list[:target_len]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZYxNqdirE4F"
      },
      "source": [
        "class Nonogram():\r\n",
        "    display_char = {\r\n",
        "        -1: \"?\",\r\n",
        "        0: \"□\",\r\n",
        "        1: \"■\"\r\n",
        "    }\r\n",
        "\r\n",
        "    def __init__(self,\r\n",
        "                 row_count: int,\r\n",
        "                 col_count: int,\r\n",
        "                 row_descriptors: List[List[int]] = None,\r\n",
        "                 col_descriptors: List[List[int]] = None,\r\n",
        "                 colored_cells: List[Tuple[int]] = None):\r\n",
        "        self.row_count = row_count\r\n",
        "        self.col_count = col_count\r\n",
        "\r\n",
        "        self.row_descriptor_len = math.ceil(col_count / 2)\r\n",
        "        self.col_descriptor_len = math.ceil(row_count / 2)\r\n",
        "\r\n",
        "        if not row_descriptors:\r\n",
        "            row_descriptors = [[] for _ in range(row_count)]\r\n",
        "        if not col_descriptors:\r\n",
        "            col_descriptors = [[] for _ in range(col_count)]\r\n",
        "\r\n",
        "        self.row_descriptors = [pad(row, self.row_descriptor_len)\r\n",
        "                                for row in row_descriptors]\r\n",
        "        self.col_descriptors = [pad(col, self.col_descriptor_len)\r\n",
        "                                for col in col_descriptors]\r\n",
        "\r\n",
        "        self.reset_cells()\r\n",
        "\r\n",
        "        if colored_cells:\r\n",
        "            self.colored_cells = colored_cells\r\n",
        "\r\n",
        "    def reset_cells(self):\r\n",
        "        self.cells = np.ones((self.row_count, self.col_count), dtype=int) * -1\r\n",
        "\r\n",
        "    @property\r\n",
        "    def colored_cells(self) -> List[Tuple[int]]:\r\n",
        "        solutions = []\r\n",
        "        for i in range(len(self.row_descriptors)):\r\n",
        "            for j in range(len(self.col_descriptors)):\r\n",
        "                if self.cells[i][j] == 1:\r\n",
        "                    solutions.append((i, j))\r\n",
        "        return solutions\r\n",
        "\r\n",
        "    @colored_cells.setter\r\n",
        "    def colored_cells(self, solutions):\r\n",
        "        for i in range(self.row_count):\r\n",
        "            for j in range(self.col_count):\r\n",
        "                self.cells[i][j] = 1 if (i, j) in solutions else 0\r\n",
        "\r\n",
        "    def print(self, show_zeros=False) -> None:\r\n",
        "        row_descriptor_len = self.row_descriptor_len\r\n",
        "        col_descriptor_len = self.col_descriptor_len\r\n",
        "\r\n",
        "        output = \"\"\r\n",
        "\r\n",
        "        # column numbers\r\n",
        "        for i in range(col_descriptor_len-1, -1, -1):\r\n",
        "            output += \"  \" * row_descriptor_len\r\n",
        "            for col in self.col_descriptors:\r\n",
        "                output += str(col[-(i+1)]) + \" \" if len(col) > i else \"  \"\r\n",
        "\r\n",
        "            output += \"\\n\"\r\n",
        "\r\n",
        "        # row numbers\r\n",
        "        for i, row in enumerate(self.row_descriptors):\r\n",
        "            for r in range(row_descriptor_len-1, -1, -1):\r\n",
        "                output += str(row[-(r+1)]) + \" \" if len(row) > r else \"  \"\r\n",
        "\r\n",
        "            # body\r\n",
        "            for j, col in enumerate(self.col_descriptors):\r\n",
        "                output += Nonogram.display_char[self.cells[i][j]] + \" \"\r\n",
        "\r\n",
        "            output += \"\\n\"\r\n",
        "\r\n",
        "        # don't display 0 values\r\n",
        "        if not show_zeros:\r\n",
        "            output = re.sub(r\"(?<=[^0-9])0\", \" \", output)\r\n",
        "        print(output)\r\n",
        "\r\n",
        "    def is_solved(self) -> bool:\r\n",
        "        if np.isin(-1, self.cells):\r\n",
        "            return False\r\n",
        "\r\n",
        "        real_row_descriptors = self.__calculate_row_descriptors()\r\n",
        "\r\n",
        "        if real_row_descriptors != self.row_descriptors:\r\n",
        "            return False\r\n",
        "\r\n",
        "        real_col_descriptors = self.__calculate_col_descriptors()\r\n",
        "\r\n",
        "        if real_col_descriptors != self.col_descriptors:\r\n",
        "            return False\r\n",
        "\r\n",
        "        return True\r\n",
        "\r\n",
        "    def calculate_descriptors(self):\r\n",
        "        self.row_descriptors = self.__calculate_row_descriptors()\r\n",
        "        self.col_descriptors = self.__calculate_col_descriptors()\r\n",
        "\r\n",
        "        return self.row_descriptors, self.col_descriptors\r\n",
        "\r\n",
        "    def __calculate_row_descriptors(self):\r\n",
        "        row_descriptors = []\r\n",
        "\r\n",
        "        for row in self.cells:\r\n",
        "            row_descriptors.append(self.__calculate_descriptor(row))\r\n",
        "\r\n",
        "        return row_descriptors\r\n",
        "\r\n",
        "    def __calculate_col_descriptors(self):\r\n",
        "        col_descriptors = []\r\n",
        "\r\n",
        "        for col in self.cells.T:\r\n",
        "            col_descriptors.append(self.__calculate_descriptor(col))\r\n",
        "\r\n",
        "        return col_descriptors\r\n",
        "\r\n",
        "    def __calculate_descriptor(self, list: List[int]):\r\n",
        "        descriptor = []\r\n",
        "        open_piece = False\r\n",
        "        pad_len = math.ceil(len(list) / 2)\r\n",
        "\r\n",
        "        for elem in list:\r\n",
        "            if elem == 1:\r\n",
        "                if open_piece:\r\n",
        "                    descriptor[-1] += 1\r\n",
        "                else:\r\n",
        "                    descriptor.append(1)\r\n",
        "                    open_piece = True\r\n",
        "            else:\r\n",
        "                open_piece = False\r\n",
        "\r\n",
        "        return pad(descriptor, pad_len)\r\n",
        "\r\n",
        "    def solve_line(self, index: int):\r\n",
        "        if index < self.row_count:\r\n",
        "            row = self.cells[index]\r\n",
        "            row_descriptor = self.row_descriptors[index]\r\n",
        "\r\n",
        "            solved_row = self.__solve_line(row, row_descriptor)\r\n",
        "            reward = np.sum(row == -1) - np.sum(solved_row == -1)\r\n",
        "\r\n",
        "            self.cells[index] = solved_row\r\n",
        "            return reward\r\n",
        "        else:\r\n",
        "            index -= self.row_count\r\n",
        "            col = self.cells[:, index]\r\n",
        "            col_descriptor = self.col_descriptors[index]\r\n",
        "\r\n",
        "            solved_col = self.__solve_line(col, col_descriptor)\r\n",
        "            reward = np.sum(col == -1) - np.sum(solved_col == -1)\r\n",
        "\r\n",
        "            self.cells[:, index] = solved_col\r\n",
        "            return reward\r\n",
        "\r\n",
        "    def __solve_line(self, line, line_descriptor):\r\n",
        "        # More efficient algorithm could be implemented\r\n",
        "        possible_lines = []\r\n",
        "        filled_cell_count = sum(line_descriptor)\r\n",
        "\r\n",
        "        line_indexes = range(len(line))\r\n",
        "\r\n",
        "        for filled_indexes in itertools.combinations(line_indexes, filled_cell_count):\r\n",
        "            possible_solution = [0 for _ in range(len(line))]\r\n",
        "\r\n",
        "            for i in filled_indexes:\r\n",
        "                possible_solution[i] = 1\r\n",
        "\r\n",
        "            if pad(self.__calculate_descriptor(possible_solution),\r\n",
        "                   len(line_descriptor)) == line_descriptor:\r\n",
        "\r\n",
        "                matches_line = True\r\n",
        "                for r, s in zip(line, possible_solution):\r\n",
        "                    if r != -1 and r != s:\r\n",
        "                        matches_line = False\r\n",
        "                        break\r\n",
        "\r\n",
        "                if matches_line:\r\n",
        "                    possible_lines.append(np.array(possible_solution))\r\n",
        "\r\n",
        "        result = [True] * len(possible_lines[0])\r\n",
        "        last_line = possible_lines[0]\r\n",
        "\r\n",
        "        for curr_line in possible_lines:\r\n",
        "            for i, (curr, last) in enumerate(zip(curr_line, last_line)):\r\n",
        "                if curr != last:\r\n",
        "                    result[i] = False\r\n",
        "            last_line = curr_line\r\n",
        "\r\n",
        "        solved_line = [e if result[i] else -1 for i,\r\n",
        "                       e in enumerate(possible_lines[0])]\r\n",
        "\r\n",
        "        return solved_line"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL_bdfFUrUGc"
      },
      "source": [
        "### Generating data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fAowE16rS1O"
      },
      "source": [
        "def random_nonogram(row_count, col_count) -> Nonogram:\r\n",
        "    cell_count = row_count*col_count\r\n",
        "\r\n",
        "    # nonograms with half of the cells colored are the hardest\r\n",
        "    colored_cell_count = np.random.binomial(cell_count, 0.5)\r\n",
        "\r\n",
        "    fields = list(itertools.product(range(row_count), range(col_count)))\r\n",
        "\r\n",
        "    colored_fields = random.sample(fields, k=colored_cell_count)\r\n",
        "\r\n",
        "    nonogram = Nonogram(\r\n",
        "        row_count,\r\n",
        "        col_count,\r\n",
        "        colored_cells=colored_fields)\r\n",
        "\r\n",
        "    nonogram.calculate_descriptors()\r\n",
        "\r\n",
        "    return nonogram"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVDvFOhsx4Q7"
      },
      "source": [
        "ROWS = 4\r\n",
        "COLS = 4"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcXoJXuorZn6",
        "outputId": "d5c1c981-4abd-473a-dad7-12a8eca2b23b"
      },
      "source": [
        "nonogram = random_nonogram(ROWS, COLS)\r\n",
        "\r\n",
        "nonogram.print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            \n",
            "    1   2 2 \n",
            "1 1 ■ □ □ ■ \n",
            "  1 □ □ □ ■ \n",
            "  1 □ □ ■ □ \n",
            "  1 □ □ ■ □ \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44MoobmpriBM"
      },
      "source": [
        "nonograms = [random_nonogram(ROWS, COLS) for _ in range(400000)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1WrSMDZsE1F"
      },
      "source": [
        "TRAIN_SPLIT = 0.7\r\n",
        "VALID_SPLIT = 0.2\r\n",
        "N = len(nonograms)\r\n",
        "\r\n",
        "train_nonograms = nonograms[:int(N*TRAIN_SPLIT)]\r\n",
        "valid_nonograms = nonograms[int(N*TRAIN_SPLIT):int(N*(TRAIN_SPLIT+VALID_SPLIT))]\r\n",
        "test_nonograms = nonograms[int(N*(TRAIN_SPLIT+VALID_SPLIT)):]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZfDQLHvuGfA"
      },
      "source": [
        "def x_from_nonogram(nonogram: Nonogram):\r\n",
        "  flat_row_descriptor = np.array(nonogram.row_descriptors).flatten()\r\n",
        "  flat_col_descriptor = np.array(nonogram.col_descriptors).flatten()\r\n",
        "  \r\n",
        "  return np.concatenate((flat_row_descriptor, flat_col_descriptor))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0brFgNsuxWqf"
      },
      "source": [
        "def y_from_nonogram(nonogram: Nonogram):\r\n",
        "  return np.array(nonogram.cells).flatten()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YdMS-3zuO0O"
      },
      "source": [
        "x_train = np.array([x_from_nonogram(n) for n in train_nonograms])\r\n",
        "y_train = np.array([y_from_nonogram(n) for n in train_nonograms])\r\n",
        "\r\n",
        "x_valid = np.array([x_from_nonogram(n) for n in valid_nonograms])\r\n",
        "y_valid = np.array([y_from_nonogram(n) for n in valid_nonograms])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB4hCnPPk2Lc"
      },
      "source": [
        "### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBZYGjisssXj"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Embedding\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from datetime import datetime"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbqoJLd27O01",
        "outputId": "19a2fc18-abb3-4f28-a60c-e521f4a4f8b4"
      },
      "source": [
        "x_train = x_train.reshape(-1,2,8,1)\r\n",
        "x_valid = x_valid.reshape(-1,2,8,1)\r\n",
        "\r\n",
        "x_train.shape, x_valid.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((280000, 2, 8, 1), (79999, 2, 8, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfgRbUYCxvnp"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv2D(256, kernel_size=(2,2), strides=(2,2), activation='relu', input_shape=(2,8,1)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation='relu'))\r\n",
        "model.add(Dense(y_train.shape[1], activation='sigmoid'))\r\n",
        "\r\n",
        "optimizer = Adam(learning_rate=0.006)\r\n",
        "model.compile(loss='mae', optimizer=optimizer)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MbvNkbw0jf5",
        "outputId": "1cc78c90-b6dd-4285-db0a-7729b57c05fe"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 1, 4, 256)         1280      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                4112      \n",
            "=================================================================\n",
            "Total params: 267,792\n",
            "Trainable params: 267,792\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n46ViUmnl6mC"
      },
      "source": [
        "### Traning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzzDMUJJmU66"
      },
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olBkyet0KXEm"
      },
      "source": [
        "# %load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJQ4hupGKSmX"
      },
      "source": [
        "# %tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wvXmC0emy8P"
      },
      "source": [
        "# Define callbacks\r\n",
        "tb = TensorBoard(log_dir='logs', histogram_freq=1, write_graph=1)\r\n",
        "early_stopping = EarlyStopping(patience=30, verbose=1)\r\n",
        "checkpoint = ModelCheckpoint(filepath='cnn_model_best',\r\n",
        "                             save_best_only=True, verbose=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sq75bCYgySYh",
        "outputId": "b81ee70d-3960-4ece-a951-9145f79d4171"
      },
      "source": [
        "model.fit(x_train, y_train, \r\n",
        "          validation_data=(x_valid, y_valid),\r\n",
        "          batch_size=512, epochs=3000,\r\n",
        "          callbacks=[tb, early_stopping, checkpoint], verbose=2)\r\n",
        "\r\n",
        "model.to_json()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.0396s). Check your callbacks.\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.06573, saving model to cnn_model_best\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.1007 - val_loss: 0.0657\n",
            "Epoch 2/3000\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.06573 to 0.05505, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0609 - val_loss: 0.0550\n",
            "Epoch 3/3000\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.05505 to 0.04918, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0528 - val_loss: 0.0492\n",
            "Epoch 4/3000\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.04918 to 0.04616, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0482 - val_loss: 0.0462\n",
            "Epoch 5/3000\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.04616 to 0.04566, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0457 - val_loss: 0.0457\n",
            "Epoch 6/3000\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.04566 to 0.04261, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0438 - val_loss: 0.0426\n",
            "Epoch 7/3000\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.04261 to 0.04207, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0425 - val_loss: 0.0421\n",
            "Epoch 8/3000\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.04207 to 0.04198, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0416 - val_loss: 0.0420\n",
            "Epoch 9/3000\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.04198 to 0.04085, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0408 - val_loss: 0.0409\n",
            "Epoch 10/3000\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.04085 to 0.03933, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0401 - val_loss: 0.0393\n",
            "Epoch 11/3000\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.03933\n",
            "547/547 - 2s - loss: 0.0397 - val_loss: 0.0407\n",
            "Epoch 12/3000\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.03933\n",
            "547/547 - 2s - loss: 0.0391 - val_loss: 0.0395\n",
            "Epoch 13/3000\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.03933 to 0.03860, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0390 - val_loss: 0.0386\n",
            "Epoch 14/3000\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.03860 to 0.03826, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0386 - val_loss: 0.0383\n",
            "Epoch 15/3000\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.03826\n",
            "547/547 - 2s - loss: 0.0382 - val_loss: 0.0384\n",
            "Epoch 16/3000\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.03826 to 0.03820, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0379 - val_loss: 0.0382\n",
            "Epoch 17/3000\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.03820\n",
            "547/547 - 2s - loss: 0.0379 - val_loss: 0.0384\n",
            "Epoch 18/3000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.03820\n",
            "547/547 - 2s - loss: 0.0376 - val_loss: 0.0385\n",
            "Epoch 19/3000\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.03820\n",
            "547/547 - 2s - loss: 0.0375 - val_loss: 0.0383\n",
            "Epoch 20/3000\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.03820 to 0.03794, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0374 - val_loss: 0.0379\n",
            "Epoch 21/3000\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.03794 to 0.03737, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0372 - val_loss: 0.0374\n",
            "Epoch 22/3000\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.03737\n",
            "547/547 - 2s - loss: 0.0372 - val_loss: 0.0379\n",
            "Epoch 23/3000\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.03737\n",
            "547/547 - 2s - loss: 0.0370 - val_loss: 0.0374\n",
            "Epoch 24/3000\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.03737 to 0.03708, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0367 - val_loss: 0.0371\n",
            "Epoch 25/3000\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.03708\n",
            "547/547 - 2s - loss: 0.0366 - val_loss: 0.0377\n",
            "Epoch 26/3000\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.03708\n",
            "547/547 - 2s - loss: 0.0366 - val_loss: 0.0371\n",
            "Epoch 27/3000\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.03708\n",
            "547/547 - 2s - loss: 0.0365 - val_loss: 0.0372\n",
            "Epoch 28/3000\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.03708\n",
            "547/547 - 2s - loss: 0.0361 - val_loss: 0.0378\n",
            "Epoch 29/3000\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.03708\n",
            "547/547 - 2s - loss: 0.0363 - val_loss: 0.0372\n",
            "Epoch 30/3000\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.03708\n",
            "547/547 - 1s - loss: 0.0360 - val_loss: 0.0374\n",
            "Epoch 31/3000\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.03708 to 0.03669, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0365 - val_loss: 0.0367\n",
            "Epoch 32/3000\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.03669\n",
            "547/547 - 2s - loss: 0.0360 - val_loss: 0.0373\n",
            "Epoch 33/3000\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.03669\n",
            "547/547 - 2s - loss: 0.0361 - val_loss: 0.0370\n",
            "Epoch 34/3000\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.03669 to 0.03666, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0358 - val_loss: 0.0367\n",
            "Epoch 35/3000\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.03666\n",
            "547/547 - 2s - loss: 0.0359 - val_loss: 0.0368\n",
            "Epoch 36/3000\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.03666 to 0.03643, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0359 - val_loss: 0.0364\n",
            "Epoch 37/3000\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.03643\n",
            "547/547 - 2s - loss: 0.0358 - val_loss: 0.0365\n",
            "Epoch 38/3000\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.03643\n",
            "547/547 - 2s - loss: 0.0358 - val_loss: 0.0365\n",
            "Epoch 39/3000\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.03643\n",
            "547/547 - 1s - loss: 0.0356 - val_loss: 0.0366\n",
            "Epoch 40/3000\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.03643\n",
            "547/547 - 1s - loss: 0.0357 - val_loss: 0.0371\n",
            "Epoch 41/3000\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.03643\n",
            "547/547 - 1s - loss: 0.0355 - val_loss: 0.0365\n",
            "Epoch 42/3000\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.03643\n",
            "547/547 - 2s - loss: 0.0355 - val_loss: 0.0369\n",
            "Epoch 43/3000\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.03643\n",
            "547/547 - 1s - loss: 0.0356 - val_loss: 0.0372\n",
            "Epoch 44/3000\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.03643\n",
            "547/547 - 2s - loss: 0.0355 - val_loss: 0.0369\n",
            "Epoch 45/3000\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.03643 to 0.03641, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0355 - val_loss: 0.0364\n",
            "Epoch 46/3000\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.03641\n",
            "547/547 - 2s - loss: 0.0354 - val_loss: 0.0367\n",
            "Epoch 47/3000\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.03641\n",
            "547/547 - 2s - loss: 0.0354 - val_loss: 0.0366\n",
            "Epoch 48/3000\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.03641 to 0.03627, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0354 - val_loss: 0.0363\n",
            "Epoch 49/3000\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.03627\n",
            "547/547 - 1s - loss: 0.0353 - val_loss: 0.0367\n",
            "Epoch 50/3000\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.03627 to 0.03598, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0353 - val_loss: 0.0360\n",
            "Epoch 51/3000\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.03598\n",
            "547/547 - 2s - loss: 0.0354 - val_loss: 0.0371\n",
            "Epoch 52/3000\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.03598\n",
            "547/547 - 2s - loss: 0.0353 - val_loss: 0.0366\n",
            "Epoch 53/3000\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.03598\n",
            "547/547 - 2s - loss: 0.0352 - val_loss: 0.0365\n",
            "Epoch 54/3000\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.03598\n",
            "547/547 - 1s - loss: 0.0352 - val_loss: 0.0364\n",
            "Epoch 55/3000\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.03598\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0363\n",
            "Epoch 56/3000\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.03598\n",
            "547/547 - 2s - loss: 0.0352 - val_loss: 0.0368\n",
            "Epoch 57/3000\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.03598\n",
            "547/547 - 1s - loss: 0.0353 - val_loss: 0.0371\n",
            "Epoch 58/3000\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.03598\n",
            "547/547 - 1s - loss: 0.0355 - val_loss: 0.0360\n",
            "Epoch 59/3000\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.03598\n",
            "547/547 - 1s - loss: 0.0351 - val_loss: 0.0369\n",
            "Epoch 60/3000\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.03598 to 0.03593, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0354 - val_loss: 0.0359\n",
            "Epoch 61/3000\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.03593\n",
            "547/547 - 2s - loss: 0.0353 - val_loss: 0.0361\n",
            "Epoch 62/3000\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.03593\n",
            "547/547 - 1s - loss: 0.0353 - val_loss: 0.0371\n",
            "Epoch 63/3000\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.03593\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0362\n",
            "Epoch 64/3000\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.03593\n",
            "547/547 - 1s - loss: 0.0353 - val_loss: 0.0362\n",
            "Epoch 65/3000\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.03593\n",
            "547/547 - 1s - loss: 0.0352 - val_loss: 0.0362\n",
            "Epoch 66/3000\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.03593\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0372\n",
            "Epoch 67/3000\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.03593 to 0.03589, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0359\n",
            "Epoch 68/3000\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.03589\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0365\n",
            "Epoch 69/3000\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0361\n",
            "Epoch 70/3000\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.03589\n",
            "547/547 - 2s - loss: 0.0350 - val_loss: 0.0364\n",
            "Epoch 71/3000\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0351 - val_loss: 0.0372\n",
            "Epoch 72/3000\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0351 - val_loss: 0.0369\n",
            "Epoch 73/3000\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0352 - val_loss: 0.0362\n",
            "Epoch 74/3000\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0352 - val_loss: 0.0362\n",
            "Epoch 75/3000\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0365\n",
            "Epoch 76/3000\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0364\n",
            "Epoch 77/3000\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0367\n",
            "Epoch 78/3000\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.03589\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0360\n",
            "Epoch 79/3000\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0364\n",
            "Epoch 80/3000\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0352 - val_loss: 0.0361\n",
            "Epoch 81/3000\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.03589\n",
            "547/547 - 2s - loss: 0.0353 - val_loss: 0.0363\n",
            "Epoch 82/3000\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0352 - val_loss: 0.0363\n",
            "Epoch 83/3000\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0367\n",
            "Epoch 84/3000\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.03589\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0364\n",
            "Epoch 85/3000\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.03589\n",
            "547/547 - 2s - loss: 0.0348 - val_loss: 0.0364\n",
            "Epoch 86/3000\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0351 - val_loss: 0.0361\n",
            "Epoch 87/3000\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.03589\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0361\n",
            "Epoch 88/3000\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0360\n",
            "Epoch 89/3000\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.03589\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0367\n",
            "Epoch 90/3000\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.03589 to 0.03585, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0347 - val_loss: 0.0358\n",
            "Epoch 91/3000\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.03585\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0365\n",
            "Epoch 92/3000\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.03585\n",
            "547/547 - 1s - loss: 0.0351 - val_loss: 0.0363\n",
            "Epoch 93/3000\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.03585 to 0.03550, saving model to cnn_model_best\n",
            "INFO:tensorflow:Assets written to: cnn_model_best/assets\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0355\n",
            "Epoch 94/3000\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0360\n",
            "Epoch 95/3000\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0367\n",
            "Epoch 96/3000\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0347 - val_loss: 0.0362\n",
            "Epoch 97/3000\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0366\n",
            "Epoch 98/3000\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0348 - val_loss: 0.0364\n",
            "Epoch 99/3000\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0360\n",
            "Epoch 100/3000\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0364\n",
            "Epoch 101/3000\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0352 - val_loss: 0.0367\n",
            "Epoch 102/3000\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0357\n",
            "Epoch 103/3000\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0348 - val_loss: 0.0360\n",
            "Epoch 104/3000\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0362\n",
            "Epoch 105/3000\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0346 - val_loss: 0.0367\n",
            "Epoch 106/3000\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0347 - val_loss: 0.0360\n",
            "Epoch 107/3000\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0349 - val_loss: 0.0365\n",
            "Epoch 108/3000\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0363\n",
            "Epoch 109/3000\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0347 - val_loss: 0.0358\n",
            "Epoch 110/3000\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0372\n",
            "Epoch 111/3000\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0363\n",
            "Epoch 112/3000\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0358\n",
            "Epoch 113/3000\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0346 - val_loss: 0.0361\n",
            "Epoch 114/3000\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0365\n",
            "Epoch 115/3000\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0351 - val_loss: 0.0369\n",
            "Epoch 116/3000\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0351 - val_loss: 0.0358\n",
            "Epoch 117/3000\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0363\n",
            "Epoch 118/3000\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0349 - val_loss: 0.0363\n",
            "Epoch 119/3000\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0361\n",
            "Epoch 120/3000\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0348 - val_loss: 0.0367\n",
            "Epoch 121/3000\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.03550\n",
            "547/547 - 2s - loss: 0.0351 - val_loss: 0.0370\n",
            "Epoch 122/3000\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0350 - val_loss: 0.0363\n",
            "Epoch 123/3000\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.03550\n",
            "547/547 - 1s - loss: 0.0353 - val_loss: 0.0375\n",
            "Epoch 00123: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 2, 8, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"conv2d_input\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d\", \"trainable\": true, \"batch_input_shape\": [null, 2, 8, 1], \"dtype\": \"float32\", \"filters\": 256, \"kernel_size\": [2, 2], \"strides\": [2, 2], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 256, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 16, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "287KI5WInPl2"
      },
      "source": [
        "### Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjWWXewtnTFx"
      },
      "source": [
        "from google.colab import drive\r\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECpy8c-ctSAR"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYNAe504rP67"
      },
      "source": [
        "MODEL_PATH = 'cnn_model_best'\r\n",
        "\r\n",
        "model = load_model(MODEL_PATH)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l05omxEnsaXI"
      },
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQXCd8VBuPbp"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib.ticker import PercentFormatter"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYd7NHXO3vQe"
      },
      "source": [
        "x_test = np.array([x_from_nonogram(n) for n in test_nonograms])\r\n",
        "y_test = np.array([y_from_nonogram(n) for n in test_nonograms])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NAwMjmjftfe"
      },
      "source": [
        "x_test = x_test.reshape(-1,2,8,1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqcZENFw4PKl"
      },
      "source": [
        "y_predicted = model.predict(x_test)\r\n",
        "y_predicted = np.rint(y_predicted).astype(int)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzMDbDbduM1c"
      },
      "source": [
        "missed_cells = []\r\n",
        "\r\n",
        "for predicted_cells, real_cells in zip(y_predicted, y_test):\r\n",
        "  mae = mean_absolute_error(predicted_cells, real_cells)\r\n",
        "\r\n",
        "  missed_cells.append(int(mae*len(real_cells)))\r\n",
        "\r\n",
        "correct_guesses = len([c for c in missed_cells if c == 0])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "d1zcewYpvLR0",
        "outputId": "8526fc9e-b145-4204-d927-e3a3ac1ac466"
      },
      "source": [
        "plt.hist(missed_cells, \r\n",
        "         bins=y_predicted.shape[1],\r\n",
        "         weights=np.ones(len(missed_cells)) / len(missed_cells),\r\n",
        "         edgecolor='white', color='orange')\r\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\r\n",
        "plt.title(f'The model solved {100*correct_guesses/len(missed_cells):.2f}% of nonograms')\r\n",
        "plt.xlabel('Number of incorrect fields')\r\n",
        "plt.show();"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h2gqfD42-OF"
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI9aZnZa0pjd"
      },
      "source": [
        "def solve_nonogram(n: Nonogram):\r\n",
        "  start = time()\r\n",
        "  x = np.array([x_from_nonogram(n)]).reshape(-1,2,8,1)\r\n",
        "  y = model.predict(x)\r\n",
        "  n.cells = np.rint(y).astype(int).reshape(4, 4)\r\n",
        "  end = time()\r\n",
        "  if n.is_solved():\r\n",
        "    print(f\"Solved in {end - start}\")\r\n",
        "  else:\r\n",
        "    print(\"Could not solve\")\r\n",
        "  return n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCRe2Pye2lmb",
        "outputId": "1ee493d0-6c43-4b17-bed5-9324410dedf2"
      },
      "source": [
        "for i in range(100):\r\n",
        "  r_nono = random_nonogram(4, 4)\r\n",
        "  r_nono.cells = []\r\n",
        "  solve_nonogram(r_nono)\r\n",
        "\r\n",
        "  r_nono.print()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solved in 0.037216901779174805\n",
            "          1 \n",
            "    1 2 1 2 \n",
            "2 1 ■ ■ □ ■ \n",
            "  2 □ ■ ■ □ \n",
            "  1 □ □ □ ■ \n",
            "  1 □ □ □ ■ \n",
            "\n",
            "Could not solve\n",
            "            \n",
            "    1 1   4 \n",
            "1 1 ■ □ □ ■ \n",
            "  1 □ □ □ ■ \n",
            "  1 □ □ □ ■ \n",
            "1 1 ■ ■ □ ■ \n",
            "\n",
            "Solved in 0.026059627532958984\n",
            "      2     \n",
            "    3 1 1 2 \n",
            "2 1 ■ ■ □ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "  1 ■ □ □ □ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.027445316314697266\n",
            "      1   2 \n",
            "    2 2 1 1 \n",
            "2 1 ■ ■ □ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "  1 □ ■ □ □ \n",
            "1 1 □ ■ □ ■ \n",
            "\n",
            "Solved in 0.02611994743347168\n",
            "      1     \n",
            "    2 1 4 3 \n",
            "  3 ■ ■ ■ □ \n",
            "1 2 ■ □ ■ ■ \n",
            "  2 □ □ ■ ■ \n",
            "  3 □ ■ ■ ■ \n",
            "\n",
            "Solved in 0.025994300842285156\n",
            "      1 1   \n",
            "    2 1 1 3 \n",
            "1 1 □ ■ □ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "1 1 ■ □ □ ■ \n",
            "  2 □ ■ ■ □ \n",
            "\n",
            "Solved in 0.028967618942260742\n",
            "    1 1   2 \n",
            "    2 1 3 1 \n",
            "1 2 ■ □ ■ ■ \n",
            "  3 □ ■ ■ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "\n",
            "Solved in 0.026598453521728516\n",
            "          1 \n",
            "    1 2   1 \n",
            "1 1 □ ■ □ ■ \n",
            "  2 ■ ■ □ □ \n",
            "  1 □ □ □ ■ \n",
            "    □ □ □ □ \n",
            "\n",
            "Solved in 0.03345131874084473\n",
            "    1     1 \n",
            "    1 4 1 2 \n",
            "2 1 ■ ■ □ ■ \n",
            "  1 □ ■ □ □ \n",
            "  4 ■ ■ ■ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "\n",
            "Solved in 0.025559186935424805\n",
            "    1   2   \n",
            "    1 1 1 1 \n",
            "  3 ■ ■ ■ □ \n",
            "  1 □ □ ■ □ \n",
            "1 1 ■ □ □ ■ \n",
            "  1 □ □ ■ □ \n",
            "\n",
            "Solved in 0.026671171188354492\n",
            "        1 1 \n",
            "    2 3 1 1 \n",
            "  1 □ □ ■ □ \n",
            "1 1 □ ■ □ ■ \n",
            "  3 ■ ■ ■ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "\n",
            "Solved in 0.025647878646850586\n",
            "      1   1 \n",
            "    2 2   1 \n",
            "1 1 □ ■ □ ■ \n",
            "    □ □ □ □ \n",
            "  2 ■ ■ □ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "\n",
            "Solved in 0.026485681533813477\n",
            "            \n",
            "      3 1 2 \n",
            "1 1 □ ■ □ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "  1 □ ■ □ □ \n",
            "  1 □ □ ■ □ \n",
            "\n",
            "Solved in 0.030707359313964844\n",
            "        1   \n",
            "    1 1 1 1 \n",
            "    □ □ □ □ \n",
            "  1 □ □ ■ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "  1 □ □ ■ □ \n",
            "\n",
            "Solved in 0.026854753494262695\n",
            "          1 \n",
            "    1 1 1 2 \n",
            "  1 □ □ □ ■ \n",
            "    □ □ □ □ \n",
            "  4 ■ ■ ■ ■ \n",
            "  1 □ □ □ ■ \n",
            "\n",
            "Could not solve\n",
            "      1     \n",
            "    1 1   1 \n",
            "  1 □ ■ □ □ \n",
            "    □ □ □ □ \n",
            "  1 □ ■ □ □ \n",
            "1 1 □ ■ □ ■ \n",
            "\n",
            "Solved in 0.02899169921875\n",
            "      1 1   \n",
            "    2 1 1 1 \n",
            "  2 □ □ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "1 1 ■ □ ■ □ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.031195640563964844\n",
            "          1 \n",
            "    1 3 2 2 \n",
            "  1 □ □ □ ■ \n",
            "  1 □ ■ □ □ \n",
            "  3 □ ■ ■ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "\n",
            "Solved in 0.028594017028808594\n",
            "      2     \n",
            "      1 2 2 \n",
            "  1 □ ■ □ □ \n",
            "  3 □ ■ ■ ■ \n",
            "  2 □ □ ■ ■ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.029951095581054688\n",
            "    1 2     \n",
            "    1 1 3 1 \n",
            "  3 ■ ■ ■ □ \n",
            "  2 □ ■ ■ □ \n",
            "  2 □ □ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "\n",
            "Solved in 0.03267502784729004\n",
            "        2 1 \n",
            "    3 2 1 1 \n",
            "  4 ■ ■ ■ ■ \n",
            "  3 ■ ■ ■ □ \n",
            "  1 ■ □ □ □ \n",
            "  2 □ □ ■ ■ \n",
            "\n",
            "Solved in 0.03498983383178711\n",
            "        1   \n",
            "      1 1 2 \n",
            "  1 □ □ ■ □ \n",
            "    □ □ □ □ \n",
            "1 1 □ ■ □ ■ \n",
            "  2 □ □ ■ ■ \n",
            "\n",
            "Solved in 0.027220487594604492\n",
            "    1       \n",
            "    1 1 2 3 \n",
            "  1 □ □ □ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "  3 □ ■ ■ ■ \n",
            "  1 ■ □ □ □ \n",
            "\n",
            "Solved in 0.030447959899902344\n",
            "    1       \n",
            "    2 2 3 1 \n",
            "  2 ■ ■ □ □ \n",
            "  2 □ ■ ■ □ \n",
            "1 2 ■ □ ■ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "\n",
            "Solved in 0.027017593383789062\n",
            "    1 2     \n",
            "    2 1 2 1 \n",
            "2 1 ■ ■ □ ■ \n",
            "  2 □ ■ ■ □ \n",
            "1 1 ■ □ ■ □ \n",
            "  2 ■ ■ □ □ \n",
            "\n",
            "Solved in 0.026130199432373047\n",
            "        2   \n",
            "    2 1 1 1 \n",
            "  1 □ □ ■ □ \n",
            "1 2 ■ □ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "  1 □ □ ■ □ \n",
            "\n",
            "Could not solve\n",
            "      1 1   \n",
            "    2 1 1 1 \n",
            "  1 ■ □ □ □ \n",
            "  3 ■ ■ ■ □ \n",
            "  1 ■ □ □ □ \n",
            "  2 □ ■ ■ □ \n",
            "\n",
            "Solved in 0.02770376205444336\n",
            "            \n",
            "    2 1 2 2 \n",
            "  1 □ □ ■ □ \n",
            "  2 □ □ ■ ■ \n",
            "2 1 ■ ■ □ ■ \n",
            "  1 ■ □ □ □ \n",
            "\n",
            "Could not solve\n",
            "      1     \n",
            "    3 1 3 1 \n",
            "  2 □ ■ □ □ \n",
            "1 1 ■ □ ■ □ \n",
            "  4 ■ ■ ■ ■ \n",
            "  1 ■ □ □ □ \n",
            "\n",
            "Solved in 0.03062129020690918\n",
            "        1 1 \n",
            "    1 2 1 1 \n",
            "  1 □ □ ■ □ \n",
            "1 1 □ ■ □ ■ \n",
            "  1 □ ■ □ □ \n",
            "1 2 ■ □ ■ ■ \n",
            "\n",
            "Solved in 0.03240466117858887\n",
            "    1   1   \n",
            "    2 2 2 2 \n",
            "1 2 ■ □ ■ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "  3 ■ ■ ■ □ \n",
            "1 1 ■ □ ■ □ \n",
            "\n",
            "Solved in 0.03102731704711914\n",
            "            \n",
            "    2 2 2 2 \n",
            "1 1 ■ □ □ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "  2 □ ■ ■ □ \n",
            "    □ □ □ □ \n",
            "\n",
            "Solved in 0.028879404067993164\n",
            "    1     1 \n",
            "    1 2 2 1 \n",
            "1 2 ■ □ ■ ■ \n",
            "  1 □ □ ■ □ \n",
            "  1 □ ■ □ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "\n",
            "Could not solve\n",
            "    2   1 1 \n",
            "    1   1 1 \n",
            "1 1 ■ □ □ □ \n",
            "1 1 ■ □ □ ■ \n",
            "  1 □ □ ■ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "\n",
            "Solved in 0.028675556182861328\n",
            "      1 1   \n",
            "    3 1 2 1 \n",
            "  3 ■ ■ ■ □ \n",
            "  1 ■ □ □ □ \n",
            "  3 ■ ■ ■ □ \n",
            "  2 □ □ ■ ■ \n",
            "\n",
            "Could not solve\n",
            "            \n",
            "      2 1 2 \n",
            "  2 □ ■ ■ □ \n",
            "  1 □ ■ □ □ \n",
            "  1 □ ■ □ ■ \n",
            "  1 □ □ □ ■ \n",
            "\n",
            "Solved in 0.029526948928833008\n",
            "    2   1   \n",
            "    1 1 1 2 \n",
            "1 2 ■ □ ■ ■ \n",
            "2 1 ■ ■ □ ■ \n",
            "    □ □ □ □ \n",
            "1 1 ■ □ ■ □ \n",
            "\n",
            "Solved in 0.03332042694091797\n",
            "            \n",
            "    1 4 1 4 \n",
            "  3 □ ■ ■ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "2 1 ■ ■ □ ■ \n",
            "\n",
            "Could not solve\n",
            "      1     \n",
            "    1 1 1 1 \n",
            "1 1 □ ■ □ ■ \n",
            "  1 □ □ □ □ \n",
            "  1 □ □ □ □ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.025861740112304688\n",
            "        1 1 \n",
            "    1   1 2 \n",
            "  1 □ □ □ ■ \n",
            "  1 □ □ ■ □ \n",
            "1 1 ■ □ □ ■ \n",
            "  2 □ □ ■ ■ \n",
            "\n",
            "Solved in 0.02760481834411621\n",
            "          1 \n",
            "    3 1 2 1 \n",
            "1 1 □ ■ □ ■ \n",
            "  1 ■ □ □ □ \n",
            "1 1 ■ □ ■ □ \n",
            "1 2 ■ □ ■ ■ \n",
            "\n",
            "Solved in 0.026081562042236328\n",
            "      1   1 \n",
            "    1 1 1 1 \n",
            "1 1 □ ■ □ ■ \n",
            "    □ □ □ □ \n",
            "  1 □ □ ■ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "\n",
            "Could not solve\n",
            "      2     \n",
            "    3 1 1 1 \n",
            "  2 ■ ■ □ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "1 1 ■ □ ■ ■ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Could not solve\n",
            "      1 1   \n",
            "    2 1 1 1 \n",
            "  3 ■ ■ ■ □ \n",
            "  1 ■ □ □ □ \n",
            "  2 □ ■ ■ □ \n",
            "  1 □ □ □ □ \n",
            "\n",
            "Solved in 0.03220415115356445\n",
            "          1 \n",
            "    3 2 2 1 \n",
            "1 2 ■ □ ■ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.03352069854736328\n",
            "    1       \n",
            "    2   1   \n",
            "  1 ■ □ □ □ \n",
            "    □ □ □ □ \n",
            "  1 ■ □ □ □ \n",
            "1 1 ■ □ ■ □ \n",
            "\n",
            "Solved in 0.029986143112182617\n",
            "        1   \n",
            "    3 3 1 3 \n",
            "  2 □ ■ ■ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "1 1 ■ □ □ ■ \n",
            "\n",
            "Solved in 0.02893972396850586\n",
            "    2 1   1 \n",
            "    1 1 4 2 \n",
            "1 2 ■ □ ■ ■ \n",
            "  3 ■ ■ ■ □ \n",
            "  2 □ □ ■ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "\n",
            "Solved in 0.028811931610107422\n",
            "        1   \n",
            "    3 2 1 3 \n",
            "1 1 ■ □ □ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "2 1 ■ ■ □ ■ \n",
            "  2 □ ■ ■ □ \n",
            "\n",
            "Solved in 0.029901504516601562\n",
            "            \n",
            "    2 3 1 4 \n",
            "1 1 □ ■ □ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "1 1 ■ □ □ ■ \n",
            "\n",
            "Solved in 0.0291750431060791\n",
            "            \n",
            "    1 2 1 2 \n",
            "    □ □ □ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "  3 □ ■ ■ ■ \n",
            "    □ □ □ □ \n",
            "\n",
            "Solved in 0.03147244453430176\n",
            "    1 1     \n",
            "    1 1 2 3 \n",
            "  1 ■ □ □ □ \n",
            "  3 □ ■ ■ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "\n",
            "Could not solve\n",
            "          1 \n",
            "    1 3 4 1 \n",
            "  2 □ □ ■ ■ \n",
            "  2 □ ■ ■ □ \n",
            "  3 ■ ■ ■ □ \n",
            "  3 ■ ■ ■ □ \n",
            "\n",
            "Solved in 0.03902435302734375\n",
            "            \n",
            "    1 1 3 1 \n",
            "    □ □ □ □ \n",
            "  1 □ □ ■ □ \n",
            "1 1 ■ □ ■ □ \n",
            "  3 □ ■ ■ ■ \n",
            "\n",
            "Solved in 0.030437469482421875\n",
            "          1 \n",
            "      2 1 1 \n",
            "    □ □ □ □ \n",
            "  2 □ □ ■ ■ \n",
            "  1 □ ■ □ □ \n",
            "1 1 □ ■ □ ■ \n",
            "\n",
            "Could not solve\n",
            "            \n",
            "    3 2     \n",
            "  1 ■ □ □ □ \n",
            "  1 ■ ■ □ □ \n",
            "  2 ■ ■ □ □ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Could not solve\n",
            "          1 \n",
            "    2 2   2 \n",
            "1 1 ■ □ □ ■ \n",
            "  1 ■ ■ □ □ \n",
            "1 1 ■ ■ □ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "\n",
            "Solved in 0.027359724044799805\n",
            "      1     \n",
            "    4 1     \n",
            "  1 ■ □ □ □ \n",
            "  2 ■ ■ □ □ \n",
            "  1 ■ □ □ □ \n",
            "  2 ■ ■ □ □ \n",
            "\n",
            "Solved in 0.028362512588500977\n",
            "            \n",
            "    2 2 4 3 \n",
            "  4 ■ ■ ■ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "  2 □ □ ■ ■ \n",
            "  1 □ □ ■ □ \n",
            "\n",
            "Solved in 0.03723430633544922\n",
            "    1     1 \n",
            "    1 4   2 \n",
            "1 1 □ ■ □ ■ \n",
            "  2 ■ ■ □ □ \n",
            "1 1 □ ■ □ ■ \n",
            "2 1 ■ ■ □ ■ \n",
            "\n",
            "Solved in 0.027106761932373047\n",
            "        1 1 \n",
            "    1 1 2 1 \n",
            "  2 □ □ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "  1 □ □ ■ □ \n",
            "  2 □ □ ■ ■ \n",
            "\n",
            "Solved in 0.029144763946533203\n",
            "      1   1 \n",
            "    1 1 2 2 \n",
            "  3 □ ■ ■ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "  1 □ □ □ ■ \n",
            "1 1 □ ■ □ ■ \n",
            "\n",
            "Solved in 0.034012556076049805\n",
            "      1 2   \n",
            "    1 1 1 1 \n",
            "  1 □ □ ■ □ \n",
            "  4 ■ ■ ■ ■ \n",
            "    □ □ □ □ \n",
            "  2 □ ■ ■ □ \n",
            "\n",
            "Solved in 0.02631402015686035\n",
            "    1 1     \n",
            "    1 1 4 1 \n",
            "1 1 ■ □ ■ □ \n",
            "  2 □ ■ ■ □ \n",
            "  2 □ □ ■ ■ \n",
            "  3 ■ ■ ■ □ \n",
            "\n",
            "Solved in 0.02716851234436035\n",
            "    2 1     \n",
            "    1 1 2   \n",
            "1 1 ■ □ ■ □ \n",
            "  3 ■ ■ ■ □ \n",
            "    □ □ □ □ \n",
            "  2 ■ ■ □ □ \n",
            "\n",
            "Solved in 0.026236772537231445\n",
            "        1   \n",
            "      3 2 1 \n",
            "  2 □ ■ ■ □ \n",
            "  1 □ ■ □ □ \n",
            "  2 □ ■ ■ □ \n",
            "  2 □ □ ■ ■ \n",
            "\n",
            "Could not solve\n",
            "      1 1   \n",
            "    2 1 1 1 \n",
            "  1 ■ □ □ □ \n",
            "  3 ■ ■ ■ □ \n",
            "  1 ■ □ □ □ \n",
            "  2 □ ■ ■ □ \n",
            "\n",
            "Solved in 0.035752296447753906\n",
            "    1 1 2 1 \n",
            "    1 1 1 1 \n",
            "  4 ■ ■ ■ ■ \n",
            "  1 □ □ ■ □ \n",
            "1 1 □ ■ □ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "\n",
            "Solved in 0.03196597099304199\n",
            "        1   \n",
            "    2 4 1 1 \n",
            "  1 □ ■ □ □ \n",
            "  3 □ ■ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "  3 ■ ■ ■ □ \n",
            "\n",
            "Solved in 0.027016162872314453\n",
            "            \n",
            "    2 3 1 2 \n",
            "  1 □ □ □ ■ \n",
            "  3 □ ■ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "  2 ■ ■ □ □ \n",
            "\n",
            "Solved in 0.02746105194091797\n",
            "    1   1   \n",
            "    2 1 1 3 \n",
            "  4 ■ ■ ■ ■ \n",
            "  1 □ □ □ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "  1 ■ □ □ □ \n",
            "\n",
            "Solved in 0.030114173889160156\n",
            "      1     \n",
            "    1 2 3 4 \n",
            "  3 □ ■ ■ ■ \n",
            "  2 □ □ ■ ■ \n",
            "  3 □ ■ ■ ■ \n",
            "2 1 ■ ■ □ ■ \n",
            "\n",
            "Solved in 0.0268709659576416\n",
            "    1   1 1 \n",
            "    1 3 1 2 \n",
            "  3 □ ■ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "1 1 □ ■ □ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "\n",
            "Solved in 0.026516199111938477\n",
            "    1       \n",
            "    2 1 4 2 \n",
            "1 1 ■ □ ■ □ \n",
            "  3 □ ■ ■ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "\n",
            "Solved in 0.026916980743408203\n",
            "    1     1 \n",
            "    2 1 2 1 \n",
            "  1 ■ □ □ □ \n",
            "  2 □ □ ■ ■ \n",
            "  3 ■ ■ ■ □ \n",
            "1 1 ■ □ □ ■ \n",
            "\n",
            "Solved in 0.03075098991394043\n",
            "    2       \n",
            "    1 3 3 2 \n",
            "  1 ■ □ □ □ \n",
            "  3 ■ ■ ■ □ \n",
            "  3 □ ■ ■ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "\n",
            "Solved in 0.028942108154296875\n",
            "            \n",
            "    1 2 2 1 \n",
            "  1 □ □ ■ □ \n",
            "  1 □ □ ■ □ \n",
            "2 1 ■ ■ □ ■ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.02619338035583496\n",
            "        1   \n",
            "        1 4 \n",
            "  2 □ □ ■ ■ \n",
            "  1 □ □ □ ■ \n",
            "  2 □ □ ■ ■ \n",
            "  1 □ □ □ ■ \n",
            "\n",
            "Solved in 0.02657604217529297\n",
            "            \n",
            "    2 2 2 1 \n",
            "  1 □ □ ■ □ \n",
            "1 1 ■ □ ■ □ \n",
            "  2 ■ ■ □ □ \n",
            "1 1 □ ■ □ ■ \n",
            "\n",
            "Solved in 0.027465343475341797\n",
            "            \n",
            "    2 2 3 3 \n",
            "  2 □ □ ■ ■ \n",
            "  2 □ □ ■ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "\n",
            "Could not solve\n",
            "      1 1   \n",
            "    1 1 2 1 \n",
            "  2 □ ■ ■ □ \n",
            "  1 □ □ □ □ \n",
            "  1 □ □ ■ □ \n",
            "  3 ■ ■ ■ □ \n",
            "\n",
            "Solved in 0.026093006134033203\n",
            "            \n",
            "    1 3 1 2 \n",
            "  1 □ □ □ ■ \n",
            "2 1 ■ ■ □ ■ \n",
            "  1 □ ■ □ □ \n",
            "  2 □ ■ ■ □ \n",
            "\n",
            "Solved in 0.026010513305664062\n",
            "    1       \n",
            "    1 1 2 2 \n",
            "  3 ■ ■ ■ □ \n",
            "  1 □ □ ■ □ \n",
            "1 1 ■ □ □ ■ \n",
            "  1 □ □ □ ■ \n",
            "\n",
            "Could not solve\n",
            "      1 1   \n",
            "    1 1 1 1 \n",
            "  1 □ □ □ □ \n",
            "  2 ■ ■ □ □ \n",
            "  2 □ ■ ■ ■ \n",
            "  1 □ □ □ □ \n",
            "\n",
            "Solved in 0.02599167823791504\n",
            "    1 2     \n",
            "    1 1 1 2 \n",
            "  2 ■ ■ □ □ \n",
            "  3 □ ■ ■ ■ \n",
            "1 1 ■ □ □ ■ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.02985835075378418\n",
            "      1     \n",
            "    3 1 2 2 \n",
            "  2 ■ ■ □ □ \n",
            "1 1 ■ □ □ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "  2 □ ■ ■ □ \n",
            "\n",
            "Solved in 0.032149314880371094\n",
            "            \n",
            "    2 3 1 1 \n",
            "1 1 ■ □ □ ■ \n",
            "  2 ■ ■ □ □ \n",
            "  1 □ ■ □ □ \n",
            "  2 □ ■ ■ □ \n",
            "\n",
            "Solved in 0.03450608253479004\n",
            "          1 \n",
            "    1 2 4 2 \n",
            "  4 ■ ■ ■ ■ \n",
            "  2 □ ■ ■ □ \n",
            "  2 □ □ ■ ■ \n",
            "  2 □ □ ■ ■ \n",
            "\n",
            "Solved in 0.02917194366455078\n",
            "      1   2 \n",
            "    1 1 4 1 \n",
            "  2 □ □ ■ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "  1 □ □ ■ □ \n",
            "  3 □ ■ ■ ■ \n",
            "\n",
            "Solved in 0.03385019302368164\n",
            "    1 1     \n",
            "    2 1   2 \n",
            "  2 ■ ■ □ □ \n",
            "  1 □ □ □ ■ \n",
            "1 1 ■ □ □ ■ \n",
            "  2 ■ ■ □ □ \n",
            "\n",
            "Solved in 0.03139352798461914\n",
            "      1   1 \n",
            "    4 1 3 1 \n",
            "2 1 ■ ■ □ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "1 1 ■ □ ■ □ \n",
            "  4 ■ ■ ■ ■ \n",
            "\n",
            "Could not solve\n",
            "            \n",
            "    1 1 1 3 \n",
            "  1 □ □ □ □ \n",
            "1 1 ■ □ □ ■ \n",
            "  1 □ □ □ ■ \n",
            "  2 □ □ ■ ■ \n",
            "\n",
            "Solved in 0.02654123306274414\n",
            "          2 \n",
            "    1 1 2 1 \n",
            "  1 □ □ □ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "  1 □ □ ■ □ \n",
            "  1 □ □ □ ■ \n",
            "\n",
            "Solved in 0.02860116958618164\n",
            "          1 \n",
            "    4 2 2 1 \n",
            "1 1 ■ □ □ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "  4 ■ ■ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "\n",
            "Solved in 0.026214122772216797\n",
            "        1 1 \n",
            "    1 3 1 1 \n",
            "    □ □ □ □ \n",
            "  3 □ ■ ■ ■ \n",
            "  2 ■ ■ □ □ \n",
            "  3 □ ■ ■ ■ \n",
            "\n",
            "Solved in 0.026157617568969727\n",
            "      1     \n",
            "    3 2 2 2 \n",
            "2 1 ■ ■ □ ■ \n",
            "1 2 ■ □ ■ ■ \n",
            "  3 ■ ■ ■ □ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.025838136672973633\n",
            "    2       \n",
            "    1 3 4 1 \n",
            "  4 ■ ■ ■ ■ \n",
            "  3 ■ ■ ■ □ \n",
            "  2 □ ■ ■ □ \n",
            "1 1 ■ □ ■ □ \n",
            "\n",
            "Solved in 0.027329444885253906\n",
            "    1 1 1 1 \n",
            "    1 2 2 2 \n",
            "  4 ■ ■ ■ ■ \n",
            "    □ □ □ □ \n",
            "  4 ■ ■ ■ ■ \n",
            "  3 □ ■ ■ ■ \n",
            "\n",
            "Solved in 0.03465390205383301\n",
            "            \n",
            "    2 3 1 1 \n",
            "    □ □ □ □ \n",
            "  2 ■ ■ □ □ \n",
            "  4 ■ ■ ■ ■ \n",
            "  1 □ ■ □ □ \n",
            "\n",
            "Solved in 0.026306629180908203\n",
            "          2 \n",
            "    4 2 3 1 \n",
            "  4 ■ ■ ■ ■ \n",
            "  4 ■ ■ ■ ■ \n",
            "1 1 ■ □ ■ □ \n",
            "1 1 ■ □ □ ■ \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}